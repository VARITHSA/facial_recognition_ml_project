{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir ='images/train'\n",
    "test_dir = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_create(dir):\n",
    "    image_path =[]\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for image_name in os.listdir(os.path.join(dir,label)):\n",
    "            image_path.append(os.path.join(dir,label,image_name))\n",
    "            labels.append(label)\n",
    "        print(label,\"completed\")\n",
    "    return image_path,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "train_data['image'],train_data['label'] = dataframe_create(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.DataFrame()\n",
    "test_data['image'],test_data['label'] = dataframe_create(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image,color_mode='grayscale')\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1.0\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "print(PIL.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1fbc4360ce46ca82517102b9499373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features = extract_feature(train_data['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0ddadffc23436ebde85659d00c5c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features = extract_feature(test_data['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LabelEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train_data['label'])\n",
    "y_test = le.transform(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes= 7)\n",
    "y_test = to_categorical(y_test,num_classes= 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srivathsa\\OneDrive\\Desktop\\Master\\personel_projects\\facial_recognition\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128,kernel_size = (3,3),activation= 'relu',input_shape = (48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256,kernel_size = (3,3),activation= 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512,kernel_size = (3,3),activation= 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512,kernel_size = (3,3),activation= 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(7,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss = 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 554ms/step - accuracy: 0.2387 - loss: 1.8320 - val_accuracy: 0.2583 - val_loss: 1.8059\n",
      "Epoch 2/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 554ms/step - accuracy: 0.2478 - loss: 1.8059 - val_accuracy: 0.2717 - val_loss: 1.7571\n",
      "Epoch 3/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 553ms/step - accuracy: 0.2871 - loss: 1.7312 - val_accuracy: 0.3610 - val_loss: 1.6112\n",
      "Epoch 4/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 548ms/step - accuracy: 0.3525 - loss: 1.6246 - val_accuracy: 0.4285 - val_loss: 1.4920\n",
      "Epoch 5/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 549ms/step - accuracy: 0.4025 - loss: 1.5221 - val_accuracy: 0.4602 - val_loss: 1.3772\n",
      "Epoch 6/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 548ms/step - accuracy: 0.4407 - loss: 1.4539 - val_accuracy: 0.4922 - val_loss: 1.3114\n",
      "Epoch 7/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 552ms/step - accuracy: 0.4559 - loss: 1.4045 - val_accuracy: 0.5093 - val_loss: 1.2859\n",
      "Epoch 8/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 551ms/step - accuracy: 0.4673 - loss: 1.3878 - val_accuracy: 0.5235 - val_loss: 1.2605\n",
      "Epoch 9/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 552ms/step - accuracy: 0.4849 - loss: 1.3488 - val_accuracy: 0.5286 - val_loss: 1.2363\n",
      "Epoch 10/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 554ms/step - accuracy: 0.4909 - loss: 1.3363 - val_accuracy: 0.5434 - val_loss: 1.2236\n",
      "Epoch 11/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 549ms/step - accuracy: 0.5041 - loss: 1.3078 - val_accuracy: 0.5423 - val_loss: 1.2033\n",
      "Epoch 12/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 552ms/step - accuracy: 0.5041 - loss: 1.2950 - val_accuracy: 0.5468 - val_loss: 1.1823\n",
      "Epoch 13/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 555ms/step - accuracy: 0.5112 - loss: 1.2732 - val_accuracy: 0.5515 - val_loss: 1.1779\n",
      "Epoch 14/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 552ms/step - accuracy: 0.5182 - loss: 1.2594 - val_accuracy: 0.5641 - val_loss: 1.1575\n",
      "Epoch 15/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 551ms/step - accuracy: 0.5236 - loss: 1.2363 - val_accuracy: 0.5601 - val_loss: 1.1616\n",
      "Epoch 16/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 550ms/step - accuracy: 0.5323 - loss: 1.2290 - val_accuracy: 0.5650 - val_loss: 1.1461\n",
      "Epoch 17/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 552ms/step - accuracy: 0.5383 - loss: 1.2193 - val_accuracy: 0.5777 - val_loss: 1.1237\n",
      "Epoch 18/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 552ms/step - accuracy: 0.5402 - loss: 1.2056 - val_accuracy: 0.5702 - val_loss: 1.1381\n",
      "Epoch 19/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 552ms/step - accuracy: 0.5430 - loss: 1.2027 - val_accuracy: 0.5676 - val_loss: 1.1563\n",
      "Epoch 20/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 548ms/step - accuracy: 0.5472 - loss: 1.1845 - val_accuracy: 0.5764 - val_loss: 1.1170\n",
      "Epoch 21/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 549ms/step - accuracy: 0.5518 - loss: 1.1734 - val_accuracy: 0.5686 - val_loss: 1.1454\n",
      "Epoch 22/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 550ms/step - accuracy: 0.5586 - loss: 1.1766 - val_accuracy: 0.5819 - val_loss: 1.1111\n",
      "Epoch 23/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 550ms/step - accuracy: 0.5556 - loss: 1.1716 - val_accuracy: 0.5795 - val_loss: 1.1017\n",
      "Epoch 24/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 549ms/step - accuracy: 0.5641 - loss: 1.1575 - val_accuracy: 0.5858 - val_loss: 1.0978\n",
      "Epoch 25/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 552ms/step - accuracy: 0.5728 - loss: 1.1335 - val_accuracy: 0.5858 - val_loss: 1.0994\n",
      "Epoch 26/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 544ms/step - accuracy: 0.5704 - loss: 1.1385 - val_accuracy: 0.5923 - val_loss: 1.0867\n",
      "Epoch 27/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 578ms/step - accuracy: 0.5731 - loss: 1.1337 - val_accuracy: 0.5927 - val_loss: 1.0927\n",
      "Epoch 28/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 551ms/step - accuracy: 0.5759 - loss: 1.1191 - val_accuracy: 0.5965 - val_loss: 1.0876\n",
      "Epoch 29/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 552ms/step - accuracy: 0.5756 - loss: 1.1164 - val_accuracy: 0.5933 - val_loss: 1.0755\n",
      "Epoch 30/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 571ms/step - accuracy: 0.5774 - loss: 1.1122 - val_accuracy: 0.6003 - val_loss: 1.0777\n",
      "Epoch 31/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 549ms/step - accuracy: 0.5758 - loss: 1.1189 - val_accuracy: 0.5965 - val_loss: 1.0767\n",
      "Epoch 32/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 544ms/step - accuracy: 0.5843 - loss: 1.1095 - val_accuracy: 0.6010 - val_loss: 1.0635\n",
      "Epoch 33/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 546ms/step - accuracy: 0.5894 - loss: 1.0936 - val_accuracy: 0.5995 - val_loss: 1.0704\n",
      "Epoch 34/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 546ms/step - accuracy: 0.5946 - loss: 1.0746 - val_accuracy: 0.6013 - val_loss: 1.0717\n",
      "Epoch 35/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 545ms/step - accuracy: 0.5961 - loss: 1.0693 - val_accuracy: 0.6078 - val_loss: 1.0593\n",
      "Epoch 36/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 555ms/step - accuracy: 0.5982 - loss: 1.0668 - val_accuracy: 0.6040 - val_loss: 1.0596\n",
      "Epoch 37/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 546ms/step - accuracy: 0.6030 - loss: 1.0607 - val_accuracy: 0.5981 - val_loss: 1.0667\n",
      "Epoch 38/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 547ms/step - accuracy: 0.5987 - loss: 1.0655 - val_accuracy: 0.6094 - val_loss: 1.0509\n",
      "Epoch 39/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 546ms/step - accuracy: 0.6038 - loss: 1.0499 - val_accuracy: 0.6080 - val_loss: 1.0572\n",
      "Epoch 40/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 548ms/step - accuracy: 0.6019 - loss: 1.0439 - val_accuracy: 0.6030 - val_loss: 1.0570\n",
      "Epoch 41/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 553ms/step - accuracy: 0.6054 - loss: 1.0383 - val_accuracy: 0.6070 - val_loss: 1.0633\n",
      "Epoch 42/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 544ms/step - accuracy: 0.6090 - loss: 1.0370 - val_accuracy: 0.6025 - val_loss: 1.0646\n",
      "Epoch 43/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 546ms/step - accuracy: 0.6079 - loss: 1.0302 - val_accuracy: 0.6083 - val_loss: 1.0664\n",
      "Epoch 44/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 547ms/step - accuracy: 0.6111 - loss: 1.0346 - val_accuracy: 0.6160 - val_loss: 1.0386\n",
      "Epoch 45/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 545ms/step - accuracy: 0.6163 - loss: 1.0120 - val_accuracy: 0.6134 - val_loss: 1.0403\n",
      "Epoch 46/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 547ms/step - accuracy: 0.6141 - loss: 1.0239 - val_accuracy: 0.6102 - val_loss: 1.0541\n",
      "Epoch 47/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 546ms/step - accuracy: 0.6187 - loss: 1.0167 - val_accuracy: 0.6189 - val_loss: 1.0309\n",
      "Epoch 48/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 547ms/step - accuracy: 0.6266 - loss: 0.9995 - val_accuracy: 0.6131 - val_loss: 1.0513\n",
      "Epoch 49/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 549ms/step - accuracy: 0.6165 - loss: 1.0164 - val_accuracy: 0.6180 - val_loss: 1.0384\n",
      "Epoch 50/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 546ms/step - accuracy: 0.6190 - loss: 1.0053 - val_accuracy: 0.6173 - val_loss: 1.0271\n",
      "Epoch 51/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 548ms/step - accuracy: 0.6252 - loss: 0.9952 - val_accuracy: 0.6179 - val_loss: 1.0335\n",
      "Epoch 52/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 547ms/step - accuracy: 0.6213 - loss: 1.0120 - val_accuracy: 0.6146 - val_loss: 1.0468\n",
      "Epoch 53/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 547ms/step - accuracy: 0.6284 - loss: 0.9837 - val_accuracy: 0.6214 - val_loss: 1.0291\n",
      "Epoch 54/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 550ms/step - accuracy: 0.6405 - loss: 0.9752 - val_accuracy: 0.6192 - val_loss: 1.0350\n",
      "Epoch 55/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 546ms/step - accuracy: 0.6341 - loss: 0.9784 - val_accuracy: 0.6257 - val_loss: 1.0214\n",
      "Epoch 56/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 551ms/step - accuracy: 0.6390 - loss: 0.9655 - val_accuracy: 0.6163 - val_loss: 1.0377\n",
      "Epoch 57/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 549ms/step - accuracy: 0.6416 - loss: 0.9630 - val_accuracy: 0.6200 - val_loss: 1.0302\n",
      "Epoch 58/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 550ms/step - accuracy: 0.6383 - loss: 0.9631 - val_accuracy: 0.6193 - val_loss: 1.0265\n",
      "Epoch 59/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 554ms/step - accuracy: 0.6472 - loss: 0.9572 - val_accuracy: 0.6176 - val_loss: 1.0336\n",
      "Epoch 60/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 553ms/step - accuracy: 0.6449 - loss: 0.9551 - val_accuracy: 0.6200 - val_loss: 1.0251\n",
      "Epoch 61/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 547ms/step - accuracy: 0.6464 - loss: 0.9486 - val_accuracy: 0.6176 - val_loss: 1.0330\n",
      "Epoch 62/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 553ms/step - accuracy: 0.6491 - loss: 0.9434 - val_accuracy: 0.6237 - val_loss: 1.0214\n",
      "Epoch 63/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 556ms/step - accuracy: 0.6448 - loss: 0.9370 - val_accuracy: 0.6241 - val_loss: 1.0232\n",
      "Epoch 64/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 558ms/step - accuracy: 0.6481 - loss: 0.9430 - val_accuracy: 0.6235 - val_loss: 1.0310\n",
      "Epoch 65/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 549ms/step - accuracy: 0.6511 - loss: 0.9412 - val_accuracy: 0.6260 - val_loss: 1.0331\n",
      "Epoch 66/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 547ms/step - accuracy: 0.6530 - loss: 0.9341 - val_accuracy: 0.6261 - val_loss: 1.0285\n",
      "Epoch 67/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 551ms/step - accuracy: 0.6584 - loss: 0.9201 - val_accuracy: 0.6261 - val_loss: 1.0271\n",
      "Epoch 68/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 550ms/step - accuracy: 0.6608 - loss: 0.9141 - val_accuracy: 0.6227 - val_loss: 1.0311\n",
      "Epoch 69/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 553ms/step - accuracy: 0.6598 - loss: 0.9193 - val_accuracy: 0.6296 - val_loss: 1.0250\n",
      "Epoch 70/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 551ms/step - accuracy: 0.6676 - loss: 0.9016 - val_accuracy: 0.6267 - val_loss: 1.0217\n",
      "Epoch 71/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 550ms/step - accuracy: 0.6626 - loss: 0.9041 - val_accuracy: 0.6284 - val_loss: 1.0187\n",
      "Epoch 72/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 547ms/step - accuracy: 0.6617 - loss: 0.9031 - val_accuracy: 0.6233 - val_loss: 1.0313\n",
      "Epoch 73/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 551ms/step - accuracy: 0.6666 - loss: 0.8982 - val_accuracy: 0.6267 - val_loss: 1.0156\n",
      "Epoch 74/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 547ms/step - accuracy: 0.6753 - loss: 0.8762 - val_accuracy: 0.6260 - val_loss: 1.0255\n",
      "Epoch 75/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 556ms/step - accuracy: 0.6741 - loss: 0.8917 - val_accuracy: 0.6294 - val_loss: 1.0161\n",
      "Epoch 76/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 549ms/step - accuracy: 0.6719 - loss: 0.8866 - val_accuracy: 0.6305 - val_loss: 1.0166\n",
      "Epoch 77/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 556ms/step - accuracy: 0.6686 - loss: 0.8933 - val_accuracy: 0.6231 - val_loss: 1.0308\n",
      "Epoch 78/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 552ms/step - accuracy: 0.6725 - loss: 0.8817 - val_accuracy: 0.6275 - val_loss: 1.0200\n",
      "Epoch 79/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 554ms/step - accuracy: 0.6729 - loss: 0.8811 - val_accuracy: 0.6238 - val_loss: 1.0343\n",
      "Epoch 80/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 554ms/step - accuracy: 0.6717 - loss: 0.8847 - val_accuracy: 0.6294 - val_loss: 1.0279\n",
      "Epoch 81/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 552ms/step - accuracy: 0.6784 - loss: 0.8719 - val_accuracy: 0.6313 - val_loss: 1.0206\n",
      "Epoch 82/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 556ms/step - accuracy: 0.6812 - loss: 0.8613 - val_accuracy: 0.6327 - val_loss: 1.0211\n",
      "Epoch 83/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 555ms/step - accuracy: 0.6771 - loss: 0.8714 - val_accuracy: 0.6264 - val_loss: 1.0206\n",
      "Epoch 84/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 555ms/step - accuracy: 0.6838 - loss: 0.8504 - val_accuracy: 0.6250 - val_loss: 1.0259\n",
      "Epoch 85/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 563ms/step - accuracy: 0.6778 - loss: 0.8671 - val_accuracy: 0.6244 - val_loss: 1.0283\n",
      "Epoch 86/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 559ms/step - accuracy: 0.6830 - loss: 0.8586 - val_accuracy: 0.6343 - val_loss: 1.0146\n",
      "Epoch 87/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 562ms/step - accuracy: 0.6898 - loss: 0.8516 - val_accuracy: 0.6301 - val_loss: 1.0287\n",
      "Epoch 88/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 582ms/step - accuracy: 0.6856 - loss: 0.8537 - val_accuracy: 0.6308 - val_loss: 1.0244\n",
      "Epoch 89/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 558ms/step - accuracy: 0.6833 - loss: 0.8463 - val_accuracy: 0.6269 - val_loss: 1.0276\n",
      "Epoch 90/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 560ms/step - accuracy: 0.6876 - loss: 0.8470 - val_accuracy: 0.6271 - val_loss: 1.0274\n",
      "Epoch 91/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 558ms/step - accuracy: 0.6880 - loss: 0.8351 - val_accuracy: 0.6247 - val_loss: 1.0313\n",
      "Epoch 92/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 556ms/step - accuracy: 0.6936 - loss: 0.8350 - val_accuracy: 0.6241 - val_loss: 1.0295\n",
      "Epoch 93/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 553ms/step - accuracy: 0.6912 - loss: 0.8397 - val_accuracy: 0.6326 - val_loss: 1.0289\n",
      "Epoch 94/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 558ms/step - accuracy: 0.6948 - loss: 0.8313 - val_accuracy: 0.6311 - val_loss: 1.0225\n",
      "Epoch 95/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 558ms/step - accuracy: 0.6953 - loss: 0.8235 - val_accuracy: 0.6349 - val_loss: 1.0292\n",
      "Epoch 96/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 555ms/step - accuracy: 0.7043 - loss: 0.8145 - val_accuracy: 0.6318 - val_loss: 1.0307\n",
      "Epoch 97/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 558ms/step - accuracy: 0.7016 - loss: 0.8036 - val_accuracy: 0.6301 - val_loss: 1.0342\n",
      "Epoch 98/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 556ms/step - accuracy: 0.6962 - loss: 0.8245 - val_accuracy: 0.6291 - val_loss: 1.0269\n",
      "Epoch 99/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 555ms/step - accuracy: 0.6968 - loss: 0.8224 - val_accuracy: 0.6312 - val_loss: 1.0273\n",
      "Epoch 100/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 558ms/step - accuracy: 0.7033 - loss: 0.8020 - val_accuracy: 0.6285 - val_loss: 1.0255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18833e1bf90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size= 128,epochs = 100, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open('emotion_detection.json','w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save('emotion_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models  import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('emotion_detection.json','r')\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights('emotion_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(img):\n",
    "    img = load_img(img,color_mode='grayscale')\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original Angry image is:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "model predicted: angry\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x188a385aad0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "image = 'images/train/angry/22.jpg'\n",
    "print(\"The original Angry image is:\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model predicted:\",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.1-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.56.0-cp311-cp311-win_amd64.whl.metadata (103 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\srivathsa\\onedrive\\desktop\\master\\personel_projects\\facial_recognition\\.venv\\lib\\site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\srivathsa\\onedrive\\desktop\\master\\personel_projects\\facial_recognition\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\srivathsa\\onedrive\\desktop\\master\\personel_projects\\facial_recognition\\.venv\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\srivathsa\\onedrive\\desktop\\master\\personel_projects\\facial_recognition\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\srivathsa\\onedrive\\desktop\\master\\personel_projects\\facial_recognition\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.0-cp311-cp311-win_amd64.whl (8.0 MB)\n",
      "Using cached contourpy-1.3.1-cp311-cp311-win_amd64.whl (219 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.56.0-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "Using cached kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.0 pyparsing-3.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
